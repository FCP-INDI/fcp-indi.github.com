<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Running C-PAC in the Cloud &mdash; C-PAC 0.3.9 Alpha documentation</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.3.9 Alpha',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="C-PAC 0.3.9 Alpha documentation" href="index.html" />
    <link rel="next" title="Data Preprocessing" href="preproc.html" />
    <link rel="prev" title="Computer Settings" href="compute_config.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="preproc.html" title="Data Preprocessing"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="compute_config.html" title="Computer Settings"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">C-PAC 0.3.9 Alpha documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="running-c-pac-in-the-cloud">
<h1>Running C-PAC in the Cloud<a class="headerlink" href="#running-c-pac-in-the-cloud" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>An Amazon Marketplace AMI for C-PAC has been released, making it easier for researchers to use C-PAC in the cloud.  You can use the AMI to either launch a single machine for basic runs or create a high performance computing (HPC) cluster using Starcluster.  Clusters can be dynamically scaled up as your computational needs increase.  Detailed explanations of cloud computing and HPC are beyond the scope of this documentation, but we will define a few key terms before we start.  If these terms are familiar, you may skip them and proceed to later sections.</p>
<ul class="simple">
<li>Amazon Machine Instance (AMI) - A disk image of an operating system and any additional installed software that can be used to create a virtual machine.</li>
<li>Instance - A single running virtual machine whose initial state is based on the AMI that it is launched from.  Instances can be classified as spot instances or on-demand instances.  On-demand instances are reliably created the moment they are requested for a fixed rate.  Spot instances are created based on whether or not a bid that you set is accepted by Amazon.  They can be significantly cheaper than on-demand instances, but are only created when Amazon accepts your bid.</li>
<li>Instance Type - The hardware specification for a given instance. A list of the instance types made available by Amazon may be found <a class="reference external" href="http://aws.amazon.com/ec2/instance-types">here</a>.</li>
<li>Elastic Block Storage (EBS) - A form of persistent storage offered by Amazon for use with instances.</li>
<li>Head Node - The primary node of an HPC cluster, which all other nodes are connected to.  The head node will run a job scheduler (such as Sun Grid Engine) to allocate jobs to the other nodes.  Jobs may also be run on the head node.</li>
<li>Worker Node - A node in an HPC cluster to which tasks are delegated by the head node via a job scheduler.</li>
<li>Job Scheduler - A program that can allocate computational resources in an HPC cluster to jobs based on availability and distribute jobs across nodes. The C-PAC AMI uses Sun Grid Engine (SGE) as its job scheduler.</li>
<li>Job Submission Script - A shell script with a series of commands to be executed as part of the job.  Submission scripts may also include flags that activate functionality specific to the scheduler.</li>
</ul>
</div>
<div class="section" id="creating-aws-access-and-network-keys">
<h2>Creating AWS Access and Network Keys<a class="headerlink" href="#creating-aws-access-and-network-keys" title="Permalink to this headline">¶</a></h2>
<p>Before you can create a single C-PAC machine or a C-PAC HPC cluster, you must first generate credentials that will allow you to log into any AWS instance that you create.  The following steps will walk you through the process of creating all the necessary credentials and encryption keys that you will need.</p>
<ol class="arabic simple">
<li>Go to <a class="reference external" href="http://aws.amazon.com/console/">http://aws.amazon.com/console/</a></li>
<li>Click the <cite>Sign in to the AWS Console</cite> button</li>
<li>Enter your e-mail address and password.  If you do not already have an account, enter your e-mail address, select <cite>I am a new user.</cite> and click the <cite>Sign in</cite> button.</li>
<li>Amazon has different regions that it hosts its web services from (e.g. Oregon, Northern Virginia, Tokyo). In the upper right-hand corner there will be a region that you are logged into next to your user name. Change this to your preferred region.</li>
<li>Click on your name in the upper right corner and navigate to <cite>Security Credentials</cite>.  Accept the disclaimer that appears on the page.</li>
<li>Click on <cite>Access Keys</cite> and click on the blue <cite>Create New Access Key</cite> button.  Click <cite>Download Key File</cite> and move the resulting csv file to a safe and memorable location on your hard drive.</li>
<li>Click on the box in the upper left corner of AWS.  Click on <cite>EC2</cite>.  Click on <cite>Key Pairs</cite> in the left-hand column.</li>
<li>Click on the blue <cite>Create Key Pair</cite> button. Give it an appropriate name and click on the blue <cite>Create</cite> button.  A .pem file will now save to disk.  Move this file to a safe and memorable location on your hard drive.</li>
<li>On your local drive, open a terminal and run the following command: <tt class="docutils literal"><span class="pre">chmod</span> <span class="pre">600</span> <span class="pre">/path/to/pem/file</span></tt></li>
</ol>
</div>
<div class="section" id="starting-a-single-c-pac-instance-via-the-aws-console">
<h2>Starting a Single C-PAC Instance via the AWS Console<a class="headerlink" href="#starting-a-single-c-pac-instance-via-the-aws-console" title="Permalink to this headline">¶</a></h2>
<p>Now that you have generated the access keys and a pem file, you may launch a single instance via Amazon&#8217;s web interface by following the steps below.  If you are planning on processing many subjects or obtaining computationally-intensive derivatives (such as network centrality), you should consider using Starcluster instead.</p>
<ol class="arabic simple">
<li>In the left-hand column under the <cite>INSTANCES</cite> header in the AWS console, click <cite>Instances</cite>. This is a dashboard of all instances you currently have running in the AWS cloud. Click the blue <cite>Launch Instance</cite> button.</li>
<li>On the left-hand side of the new page, click on the <cite>Amazon Marketplace</cite> tab and search <cite>c-pac</cite> in the search text box.</li>
<li>Click the blue <cite>Select</cite> button next to the C-PAC AMI.  Click the blue <cite>Continue</cite> button on the next screen.</li>
<li>Now choose the instance type that you would like to use.  Note that C-PAC requires at least 8 GB of RAM- the m3.xlarge instance type has 15 GB of RAM and 4 CPUs and functions well with C-PAC for small runs and experimentation.  This instance type is equivalent to a standard desktop machine in terms of processing power. To select this type, click on the <cite>General purpose</cite> tab and select the m3.xlarge size instance and click the <cite>Next: Configure Instance Details</cite> button.  Note that for most larger runs you will want to choose a more powerful instance type, such as c3.4xlarge or c3.8xlarge.</li>
<li>The details page can be used to request spot instances, as well as other functionality (including VPN, VPC options). For a basic run you do not need to change anything, although you can tailor it according to your future needs. Hovering over the &#8216;i&#8217; icons on this page will give you more insight into the options available.  When done, click <cite>Next: Add Storage.</cite></li>
<li>On the storage page, you can allocate storage for your dataset. Note that the amount of space you allocate will have to encompass raw data, preprocessed data, and derivatives.  Click <cite>Next: Tag Instance</cite>.</li>
<li>On this page you can tag the instance with metadata (e.g., details related to the specific purpose for the instance).  Tags are key-value pairs, so any contextual data that can be encapsulated in this format can be saved. Click <cite>Next: Configure Security Group</cite>.</li>
<li>On this page, you can modify who has access to the instance. The AMI defaults allow remote access from anywhere. If you would like to customize security to allow only a certain set of IP addresses and users access to the instance, you can do so here. Click <cite>Review and Launch</cite> when you are done.</li>
<li>This final page summarizes the instance details you are about to launch. You might receive some warnings as a result of security or the instance type not being in the free tier.  These warnings can be ignored.</li>
<li>Click the <cite>Launch</cite> button. A dialogue box will ask you to choose a key pair for the instance. Every instance requires a key pair in order for you to securely log in and use it. Change the top drop down menu bar to <cite>Choose an existing key pair</cite> and select the key pair you created in the <cite>Creating AWS Access and Network Keys</cite> section in the other drop down menu.  Check the acknowledgement check box and click the blue <cite>Launch Instances</cite> button.</li>
<li>You can click the <cite>View Instances</cite> blue button on the lower right of the page after to watch your new instance start up in the instance console.</li>
<li>When the <cite>Instance State</cite> column reads <cite>running</cite> and the <cite>Status Checks</cite> column reads <cite>2/2</cite> you can access and use the instance. Click on the instance&#8217;s row.  In the bottom pane, find the <cite>Public DNS</cite> field under the <cite>Description</cite> tab and save the field value to your clipboard.</li>
</ol>
<p>There are now two different means of accessing the instance.  Either through X2Go (a desktop GUI-based session) or through ssh (a command line session).</p>
<div class="section" id="ssh">
<h3>ssh<a class="headerlink" href="#ssh" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Open a terminal and type <tt class="docutils literal"><span class="pre">ssh</span> <span class="pre">-i</span> <span class="pre">/path/to/pem/file</span> <span class="pre">ubuntu&#64;&lt;public_dns&gt;</span></tt>.</li>
<li>Type <cite>yes</cite> when asked if you trust the source.</li>
</ol>
</div>
<div class="section" id="x2go">
<h3>X2Go<a class="headerlink" href="#x2go" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Install the X2Go client using the instructions <a class="reference external" href="http://wiki.x2go.org/doku.php/doc:installation:x2goclient">here</a>.</li>
<li>Open X2go and create a new session.</li>
<li>For <cite>Host:</cite>, enter the Public DNS from earlier.</li>
<li>For <cite>Login:</cite> enter <cite>ubuntu</cite>.</li>
<li><cite>SSH port:</cite> should be <cite>22</cite>.</li>
<li>For <cite>Use RSA/DSA key for ssh connection:</cite>, select the key you generated for the instance.</li>
<li>Select <cite>LXDE</cite> for <cite>Session</cite> and click <cite>OK</cite>.</li>
</ol>
<p>When you are done, your session configuration should look similar to the following:</p>
<div class="figure">
<img alt="_images/cloud_x2go.png" src="_images/cloud_x2go.png" />
</div>
</div>
</div>
<div class="section" id="starting-a-c-pac-hpc-cluster-via-starcluster">
<h2>Starting a C-PAC HPC Cluster via Starcluster<a class="headerlink" href="#starting-a-c-pac-hpc-cluster-via-starcluster" title="Permalink to this headline">¶</a></h2>
<p>Starcluster is suggested for more sophisticated C-PAC runs.  Using Starcluster, you can parallelize your analyses by distributing subjects across multiple nodes in an HPC cluster.  The following section describes how to install and configure Starcluster to work with C-PAC, dynamically add nodes to your cluster and leverage C-PAC&#8217;s grid functionality.</p>
<div class="section" id="installing-starcluster">
<h3>Installing Starcluster<a class="headerlink" href="#installing-starcluster" title="Permalink to this headline">¶</a></h3>
<p>If you have pip installed, Starcluster can be installed via:</p>
<div class="highlight-bash"><div class="highlight"><pre>pip install starcluster
</pre></div>
</div>
<p>Note that if you are using a *nix-based OS and you are not using an environment such as Miniconda, you will need to run the above command with <tt class="docutils literal"><span class="pre">sudo</span></tt>.</p>
<p>If you do not have pip installed, see the <a class="reference external" href="http://star.mit.edu/cluster/docs/latest/installation.html">Official Starcluster Installation Instructions</a> for alternative installation methods.</p>
</div>
<div class="section" id="installing-the-c-pac-starcluster-plug-ins">
<h3>Installing the C-PAC Starcluster Plug-ins<a class="headerlink" href="#installing-the-c-pac-starcluster-plug-ins" title="Permalink to this headline">¶</a></h3>
<p>The C-PAC Starcluster plug-ins configure the SGE environment that C-PAC uses and ensure that storage space is writable.  From the terminal, download the C-PAC Starcluster plug-ins and install them by running the following commands:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nb">cd</span> /tmp
git clone https://github.com/FCP-INDI/CPAC_CLOUD
<span class="nb">cd </span>CPAC_CLOUD/sc_plugins
mv *.py ~/.starcluster/plugins
</pre></div>
</div>
</div>
<div class="section" id="creating-and-editing-your-configuration-file">
<h3>Creating and Editing Your Configuration File<a class="headerlink" href="#creating-and-editing-your-configuration-file" title="Permalink to this headline">¶</a></h3>
<p>Now you will need to create a Starcluster configuration file so that Starcluster can use your keys and know which instance types you would like to use.  To begin, type <tt class="docutils literal"><span class="pre">starcluster</span> <span class="pre">help</span></tt> and select option 2.</p>
<p>Fill in the AWS access keys from the CVS file that you created in the <cite>Creating AWS Access and Network Keys</cite> section:</p>
<div class="highlight-python"><div class="highlight"><pre>[aws info]
AWS_ACCESS_KEY_ID = &lt;your_key&gt;
AWS_SECRET_ACCESS_KEY = &lt;your_secret_key&gt;
</pre></div>
</div>
<p>You do not need to define the <tt class="docutils literal"><span class="pre">AWS_USER_ID</span></tt> field unless you want to create custom AMIs based off the C-PAC AMI.  If you would like to use a region other than us-east-1, you may specify the region here by changing <tt class="docutils literal"><span class="pre">AWS_REGION_NAME</span></tt>.</p>
<p>Point your key definition to the pem file you generated in the <cite>Creating AWS Access and Network Keys</cite> section:</p>
<div class="highlight-python"><div class="highlight"><pre>[key cpac_key]
KEY_LOCATION=/path/to/pem/file
</pre></div>
</div>
<p>Add the following cluster definition to your configuration file:</p>
<div class="highlight-python"><div class="highlight"><pre>[cluster cpac_cluster]
KEYNAME = cpac_key
PLUGINS = cpac_sge, mnt_config
CLUSTER_SIZE = 1
CLUSTER_SHELL = bash
NODE_IMAGE_ID = ami-ed993586
MASTER_INSTANCE_TYPE = t2.medium
NODE_INSTANCE_TYPE = c3.8xlarge
</pre></div>
</div>
<p>You can customize this to have additional nodes or use different instance types as per your needs.  Note that you can always add nodes later using Starcluster from the command line.  If you wish to use spot instances rather than on-demand instances, then add the following line to the cluster definition:</p>
<div class="highlight-python"><div class="highlight"><pre>SPOT = &lt;bidding_price&gt;
</pre></div>
</div>
<p>Also add the following two plug-in definitions for the C-PAC Starcluster plug-ins:</p>
<div class="highlight-python"><div class="highlight"><pre>[plugin cpac_sge]
setup_class = cpac_sge.PEInstaller
pe_url = https://raw.githubusercontent.com/FCP-INDI/CPAC_CLOUD/master/mpi_smp.conf

[plugin mnt_config]
setup_class = mnt_perm.MntPermissions
</pre></div>
</div>
</div>
<div class="section" id="attaching-persistent-storage-to-your-cluster">
<h3>Attaching Persistent Storage to Your Cluster<a class="headerlink" href="#attaching-persistent-storage-to-your-cluster" title="Permalink to this headline">¶</a></h3>
<p>By default, the cluster will not have any persistent storage (i.e., all storage devices will be destroyed when the cluster terminates). A shared directory mounted at <cite>/home</cite> on the head node can be used across nodes. If you need more storage than what is available on the head node or if you want to keep your data after the cluster is terminated, you will need to create a new volume that can be attached to all nodes in the cluster.  To do so, begin by creating an EBS-backed volume:</p>
<div class="highlight-bash"><div class="highlight"><pre>starcluster createvolume --shutdown-volume-host &lt;volume_size_in_gigabytes&gt; &lt;region&gt;
</pre></div>
</div>
<p>Type <tt class="docutils literal"><span class="pre">starcluster</span> <span class="pre">listvolumes</span></tt> and get the <cite>volume-id</cite> for the volume that you just created.  Open up your Starcluster configuration file and add the following volume definition:</p>
<div class="highlight-python"><div class="highlight"><pre>[volume cpac_volume]
VOLUME_ID = &lt;volume_id&gt;
MOUNT_PATH = /mnt
</pre></div>
</div>
<p>Append the following line to your <cite>cpac_cluster</cite> definition:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">VOLUMES</span> <span class="o">=</span> <span class="n">cpac_volume</span>
</pre></div>
</div>
<p>The <a class="reference external" href="http://star.mit.edu/cluster/docs/latest/manual/volumes.html">Starcluster documentation</a> explains how to perform other operations such as resizing and removing volumes.</p>
</div>
<div class="section" id="starting-the-c-pac-head-node">
<h3>Starting the C-PAC Head Node<a class="headerlink" href="#starting-the-c-pac-head-node" title="Permalink to this headline">¶</a></h3>
<p>To start up the head node on your C-PAC HPC cluster, use the following Starcluster command (with substitutions where necessary):</p>
<div class="highlight-bash"><div class="highlight"><pre>starcluster start -c cpac_cluster &lt;cluster_name&gt;
</pre></div>
</div>
</div>
<div class="section" id="adding-additional-nodes">
<h3>Adding Additional Nodes<a class="headerlink" href="#adding-additional-nodes" title="Permalink to this headline">¶</a></h3>
<p>To add additional nodes to your C-PAC HPC cluster, use the following Starcluster command (with substitutions where necessary):</p>
<div class="highlight-bash"><div class="highlight"><pre>starcluster addnode -n &lt;number_of_nodes_to_add&gt; &lt;cluster_name&gt;
</pre></div>
</div>
</div>
<div class="section" id="accessing-the-head-node">
<h3>Accessing the Head Node<a class="headerlink" href="#accessing-the-head-node" title="Permalink to this headline">¶</a></h3>
<p>If you wish to use the C-PAC GUI while accessing the head node, type the following command:</p>
<div class="highlight-bash"><div class="highlight"><pre>starcluster sshmaster -X -u ubuntu &lt;cluster_name&gt;
</pre></div>
</div>
<p>If you only wish to access the command line interface, you may omit the <cite>-X</cite> flag:</p>
<div class="highlight-bash"><div class="highlight"><pre>starcluster sshmaster -u ubuntu &lt;cluster_name&gt;
</pre></div>
</div>
<p>You may also use the instructions for X2Go from the <cite>Starting a Single C-PAC Instance via the AWS Console</cite> section to access the head node via a graphical shell.  To do so, obtain the public DNS for the head node by typing <tt class="docutils literal"><span class="pre">starcluster</span> <span class="pre">listclusters</span></tt>.  The public DNS will be in the last column of the row labeled <cite>master</cite>.</p>
</div>
<div class="section" id="using-c-pac-to-submit-an-sge-job">
<h3>Using C-PAC to Submit an SGE Job<a class="headerlink" href="#using-c-pac-to-submit-an-sge-job" title="Permalink to this headline">¶</a></h3>
<p>C-PAC performs the heavy lifting of creating an SGE job submission script and submitting it to the SGE job scheduler seamlessly.  There are two ways to accomplish this- either through C-PAC&#8217;s GUI or from the command line.</p>
<p><strong>Via the C-PAC GUI:</strong></p>
<ol class="arabic simple">
<li>Type <cite>cpac_gui</cite> while in the shell on the head node.</li>
<li>From the main C-PAC window, load your pipeline configuration file.</li>
<li>Under <cite>Computer Settings</cite> in the left pane, change <cite>Run C-PAC on Grid</cite> to True.  Change <cite>SGE Parallel Environment</cite> to <cite>mpi_smp</cite>.</li>
</ol>
<p>When you are done, your window should look like this:</p>
<div class="figure">
<img alt="_images/cloud_gui_sge.png" src="_images/cloud_gui_sge.png" />
</div>
<p>Save the pipeline configuration file and run an analysis as you would normally.</p>
<p><strong>Via the shell:</strong></p>
<ol class="arabic simple">
<li>Open your pipeline configuration YAML file in your preferred text editor.</li>
<li>Change the <tt class="docutils literal"><span class="pre">runOnGrid</span></tt> field to a value of <tt class="docutils literal"><span class="pre">True</span></tt>.</li>
<li>Make sure that the <tt class="docutils literal"><span class="pre">resourceManager</span></tt> field is set to <tt class="docutils literal"><span class="pre">SGE</span></tt>.</li>
<li>Set the <tt class="docutils literal"><span class="pre">parallelEnvironment</span></tt> field to <tt class="docutils literal"><span class="pre">mpi_smp</span></tt>.</li>
<li>Execute the following command to run your pipeline.</li>
</ol>
<div class="highlight-bash"><div class="highlight"><pre>cpac_run.py /path/to/pipeline_config.yml /path/to/CPAC_subject_list.yml
</pre></div>
</div>
</div>
<div class="section" id="checking-on-sge-jobs">
<h3>Checking on SGE Jobs<a class="headerlink" href="#checking-on-sge-jobs" title="Permalink to this headline">¶</a></h3>
<p>Once you are done submitting the job, you can check its status by typing <tt class="docutils literal"><span class="pre">qstat</span></tt>.  This command will produce output that looks similar to the following:</p>
<div class="highlight-python"><div class="highlight"><pre>job-ID  prior   name       user         state submit/start at     queue                          slots ja-task-ID
-----------------------------------------------------------------------------------------------------------------
      1 0.55500 submit_201 ubuntu       r     06/05/2015 20:42:13 all.q@master                       1 1
      1 0.55500 submit_201 ubuntu       r     06/05/2015 20:42:13 all.q@node001                      1 2
      2 0.55500 submit_201 ubuntu       r     06/05/2015 20:42:58 all.q@node002                      1 1
      2 0.00000 submit_201 ubuntu       qw    06/05/2015 20:42:47                                    1 2
</pre></div>
</div>
<p>The <cite>job-ID</cite> is a number assigned to your job when it is submitted to the scheduler.  The <cite>state</cite> of the job can be represented by one of several values: <cite>r</cite> means that the job is running, <cite>qw</cite> means that the job is queued and waiting, and <cite>E</cite> means that an error has occurred. The <cite>queue</cite> column indicates on which nodes of your cluster the C-PAC job is being executed.</p>
<p>If an error has occurred on any of the nodes while your pipeline executes, you should check the <cite>cluster_temp_files</cite> directory that was created in the directory from which you ran C-PAC.  This will contain copies of the job submission scripts that C-PAC generated to start your job.  It will also contain files containing the standard out and error messages for a given job.  You should check these first to determine what may have caused the error.  If these files do not help you determine what may have caused the error, feel free to ask for <a class="reference internal" href="help.html"><em>help</em></a> on the C-PAC forum.</p>
</div>
<div class="section" id="terminating-a-starcluster-instance">
<h3>Terminating a Starcluster Instance<a class="headerlink" href="#terminating-a-starcluster-instance" title="Permalink to this headline">¶</a></h3>
<p>When you are done and have exited from your cluster, the following command will stop the cluster:</p>
<div class="highlight-bash"><div class="highlight"><pre>starcluster terminate &lt;cluster_name&gt;
</pre></div>
</div>
<p>If you receive an error from Starcluster while trying to terminate the instance, the following command will force Starcluster to terminate your cluster:</p>
<div class="highlight-bash"><div class="highlight"><pre>starcluster terminate -f &lt;cluster_name&gt;
</pre></div>
</div>
<p><strong>Warning:</strong> If you are not using persistent storage (see <cite>Attaching Persistent Storage to Your Cluster</cite>) then all of your data will be lost upon termination of the cluster.  You will need to copy your data to another drive if you wish to keep it.</p>
</div>
</div>
<div class="section" id="additional-links">
<h2>Additional Links<a class="headerlink" href="#additional-links" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="http://star.mit.edu/cluster/docs/latest/manual/index.html">The StarCluster User Manual</a></li>
<li><a class="reference external" href="http://www.csb.yale.edu/userguides/sysresource/batch/doc/UserGuide_6.1.pdf">The Sun Grid Engine User Guide</a></li>
<li><a class="reference external" href="http://docs.aws.amazon.com/gettingstarted/latest/awsgsg-intro/gsg-aws-intro.html">Getting Started with AWS</a></li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/cpac_logo.jpg" alt="Logo"/>
            </a></p>
<h3><a href="index.html">Table Of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Installing C-PAC</a></li>
<li class="toctree-l1"><a class="reference internal" href="use.html">Using C-PAC</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Running C-PAC in the Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="preproc.html">Data Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="outputs.html">Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="files.html">Preconfigured Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">C-PAC Benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="help.html">Troubleshooting and Help</a></li>
<li class="toctree-l1"><a class="reference internal" href="rnotes.html">Release Notes</a></li>
</ul>

<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="preproc.html" title="Data Preprocessing"
             >next</a> |</li>
        <li class="right" >
          <a href="compute_config.html" title="Computer Settings"
             >previous</a> |</li>
        <li><a href="index.html">C-PAC 0.3.9 Alpha documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2015, C-PAC Team.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>